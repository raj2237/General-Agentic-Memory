#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GAM æ¡†æ¶ + LoCoMo æ•°æ®é›†æµ‹è¯•æ–‡ä»¶

ç»“åˆ locomoqa_v3.py çš„æ•°æ®å¤„ç†é€»è¾‘å’Œ GAM æ¡†æ¶ï¼Œæµ‹è¯•åœ¨å¤šè½®å¯¹è¯æ•°æ®ä¸Šçš„æ•ˆæœã€‚
"""

import sys
import os
import re
import json
from typing import Any, Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
from multiprocessing import cpu_count
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from gam import (
    MemoryAgent,
    ResearchAgent,
    VLLMGenerator,
    InMemoryMemoryStore,
    InMemoryPageStore,
    IndexRetriever,
    BM25Retriever,
    DenseRetriever,
    VLLMGeneratorConfig,
    OpenAIGenerator,
    OpenAIGeneratorConfig,
    IndexRetrieverConfig,
    BM25RetrieverConfig,
    DenseRetrieverConfig,
)

# ========== æ•°æ®åŠ è½½ï¼šå€Ÿé‰´è‡ª locomoqa_v3.py ==========

def load_json(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_locomo(json_path: str) -> List[Dict[str, Any]]:
    """Load LoCoMo JSON and return the list of samples."""
    data = load_json(json_path)
    if isinstance(data, dict) and "samples" in data:
        return data["samples"]
    if isinstance(data, list):
        return data
    raise ValueError("Unrecognized LoCoMo JSON shape. Expect a list or {'samples': [...]}.")

def extract_sessions(conv_obj: Dict[str, Any]) -> List[Tuple[int, str, List[Dict[str, Any]], Optional[str]]]:
    """
    Extract sessions as (idx, timestamp, turns, optional_session_summary).
    """
    sessions: List[Tuple[int, str, List[Dict[str, Any]], Optional[str]]] = []
    for k, v in conv_obj.items():
        m = re.match(r'^session_(\d+)$', k)
        if not (m and isinstance(v, list)):
            continue
        idx = int(m.group(1))
        ts = conv_obj.get(f"session_{idx}_date_time", "")
        ssum = conv_obj.get(f"session_{idx}_summary", None)
        sessions.append((idx, ts, v, ssum if isinstance(ssum, str) and ssum.strip() else None))
    sessions.sort(key=lambda x: x[0])
    return sessions

def session_to_text(idx: int, ts: str, turns: List[Dict[str, Any]], session_summary: Optional[str]) -> str:
    # å°†æ—¶é—´ä¿¡æ¯æ”¾åœ¨æœ€å‰é¢ï¼Œä½¿ç”¨æ›´çªå‡ºçš„æ ¼å¼
    lines = [f"=== SESSION {idx} - Dialogue Time(available to answer questions): {ts} ==="]
    lines.append("")  # ç©ºè¡Œåˆ†éš”
    
    for turn in turns:
        speaker = turn.get("speaker", "Unknown")
        dia_id  = turn.get("dia_id", "")
        text    = turn.get("text", "")
        lines.append(f"{speaker} ({dia_id}): {text}")
    
    if session_summary:
        lines.append("")
        lines.append(f"Session {idx} summary: {session_summary}")
    
    return "\n".join(lines).strip()

def build_session_chunks_for_sample(sample: Dict[str, Any]) -> List[str]:
    """Build session chunks from a sample."""
    conv = sample.get("conversation", {})
    sessions = extract_sessions(conv)
    chunks: List[str] = []
    for idx, ts, turns, ssum in sessions:
        chunks.append(session_to_text(idx, ts, turns, ssum))
    return chunks

def collect_qa_items_for_sample(sample: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Collect QA items from a sample."""
    qas: List[Dict[str, Any]] = []
    sid = sample.get("sample_id", None)
    for q in sample.get("qa", []):
        qas.append({
            "sample_id": sid,
            "question": q.get("question"),
            "answer": q.get("answer"),
            "category": q.get("category"),
            "evidence": q.get("evidence"),
        })
    return qas

# ========== Prompt è®¾è®¡ï¼šå®Œå…¨å€Ÿé‰´è‡ª locomoqa_v3.py ==========

def safe_json_extract(candidate: Any) -> Optional[Dict[str, Any]]:
    """å°½é‡æŠŠæ¨¡å‹è¾“å‡ºï¼ˆstring/dictï¼‰è§£ææˆ dictï¼Œå¤±è´¥è¿”å› Noneã€‚"""
    if isinstance(candidate, dict):
        return candidate
    if not isinstance(candidate, str):
        return None
    s = candidate.strip()
    l = s.find('{')
    r = s.rfind('}')
    if l == -1 or r == -1 or r <= l:
        return None
    try:
        return json.loads(s[l:r+1])
    except Exception:
        return None

def make_summary_prompt(summary: str, question: str) -> str:
    return f"""
    Based on the summary below, write an answer in the form of **a short phrase** for the following question, not a sentence. Answer with exact words from the context whenever possible.
    For questions that require answering a date or time, strictly follow the format \"15 July 2023\" and provide a specific date whenever possible. For example, if you need to answer \"last year,\" give the specific year of last year rather than just saying \"last year.\" Only provide one year, date, or time, without any extra responses.
    If the question is about the duration, answer in the form of several years, months, or days.
   
    QUESTION:
    {question}

    SUMMARY:
    {summary}

    Short answer:
    """

def make_summary_prompt_category3(summary: str, question: str) -> str:
    return f"""
    Based on the summary below, write an answer in the form of **a short phrase** for the following question, not a sentence.
    The question may need you to analyze and infer the answer from the summary.
     
    QUESTION:
    {question}

    SUMMARY:
    {summary}

    Short answer:
    """

def make_memory_only_prompt(memory_obj: Any, question: str) -> str:
    mem_str = json.dumps(memory_obj, ensure_ascii=False, indent=2) if isinstance(memory_obj, dict) else str(memory_obj)
    return f"""
    Based on the MEMORY STATE below,  write an answer in the form of a brief short phrase for the following question. Answer with exact words from the context whenever possible.
    The date should be written as an exact date.

    MEMORY STATE:
    {mem_str}

    QUESTION:
    {question}

    Short answer:
    """

def make_memory_only_prompt_category3(memory_obj: Any, question: str) -> str:
    mem_str = json.dumps(memory_obj, ensure_ascii=False, indent=2) if isinstance(memory_obj, dict) else str(memory_obj)
    return f"""
    Based on the MEMORY STATE below,  write an answer in the form of a brief short phrase for the following question. Answer with exact words from the context whenever possible.
    The date should be written as an exact date.

    MEMORY STATE:
    {mem_str}

    QUESTION:
    {question}

    Short answer:
    """

def answer_with_summary(category: Optional[int], summary: str, question: str, generator) -> str:
    """æ ¹æ®categoryé€‰æ‹©ä¸åŒçš„prompt"""
    if category == 3:
        prompt = make_summary_prompt_category3(summary, question)
    else:
        prompt = make_summary_prompt(summary, question)
    raw = generator.generate_single(prompt=prompt)
    return raw.get("text", "").strip()

def answer_with_memory(category: Optional[int], final_memory: Dict[str, Any], question: str, generator) -> str:
    """æ ¹æ®categoryé€‰æ‹©ä¸åŒçš„prompt"""
    if category == 3:
        prompt = make_memory_only_prompt_category3(final_memory, question)
    else:
        prompt = make_memory_only_prompt(final_memory, question)
    raw = generator.generate_single(prompt=prompt)
    return raw.get("text", "").strip()

# ========== æ ¸å¿ƒå¤„ç†é€»è¾‘ ==========

def process_sample(sample: Dict[str, Any], sample_index: int, outdir: str, memory_model_api: str, thread_count: int = 40):
    """
    ä½¿ç”¨ GAM æ¡†æ¶å¤„ç†å•ä¸ªæ ·æœ¬ã€‚
    
    æµç¨‹ï¼š
    1. ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†
    2. ä½¿ç”¨ ResearchAgent è¿›è¡Œæ·±åº¦ç ”ç©¶
    3. åŸºäºç ”ç©¶ç»“æœè¿›è¡Œé—®ç­”
    """
    sample_id = sample.get("sample_id", f"conv-{sample_index}")
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ ·æœ¬ #{sample_index}: {sample_id}")
    print(f"{'='*60}")
    
    try:
        # 1. æ„å»ºä¼šè¯å—
        session_chunks = build_session_chunks_for_sample(sample)
        print(f"ä¼šè¯æ•°: {len(session_chunks)}")
        if session_chunks:
            print(f"ç¬¬ä¸€ä¸ªä¼šè¯é¢„è§ˆ:\n{session_chunks[0][:400]}...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        sample_results_dir = os.path.join(outdir, sample_id)
        os.makedirs(sample_results_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {sample_results_dir}")
        
        # 2. åˆ›å»ºå…±äº«å­˜å‚¨
        memory_store = InMemoryMemoryStore(dir_path=sample_results_dir)
        page_store = InMemoryPageStore(dir_path=sample_results_dir)
        
        # 3. åˆ›å»º Generator
        print(f"\næ­¥éª¤ 1: åˆ›å»º Generator")
        memory_generator_config = VLLMGeneratorConfig(
            model_name="qwen3",
            api_key="empty",
            base_url=memory_model_api,
            temperature=0.3,
            max_tokens=256
        )
        memory_generator = VLLMGenerator(memory_generator_config.__dict__)

        print(f"[OK] Generator åˆ›å»ºå®Œæˆ")
        
        # 4. ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†ï¼ˆå°†æ¯ä¸ª session ä½œä¸ºä¸€æ¡æ¶ˆæ¯ï¼‰
        print(f"\næ­¥éª¤ 2: ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†")
        memory_agent = MemoryAgent(
            memory_store=memory_store,
            page_store=page_store,
            generator=memory_generator
        )
        
        if not os.path.exists(os.path.join(sample_results_dir, 'memory_state.json')):
            for i, session_chunk in enumerate(session_chunks, 1):
                print(f"  å¤„ç†ä¼šè¯ {i}/{len(session_chunks)}...")
                memory_update = memory_agent.memorize(session_chunk)
        
        # æŸ¥çœ‹æ„å»ºçš„è®°å¿†
        final_state = memory_store.load()
        print(f"[OK] è®°å¿†æ„å»ºå®Œæˆï¼å…± {len(final_state.abstracts)} æ¡è®°å¿†æ‘˜è¦")
        
        # æ˜¾ç¤ºè®°å¿†æ‘˜è¦
        print("\nğŸ“š è®°å¿†æ‘˜è¦:")
        for i, abstract in enumerate(final_state.abstracts, 1):
            print(f"  {i}. {abstract[:100]}...")
        
        # ä¿å­˜è®°å¿†çŠ¶æ€
        memory_state_file = os.path.join(sample_results_dir, "memory_state.json")
        with open(memory_state_file, 'w', encoding='utf-8') as f:
            json.dump(final_state.model_dump(), f, ensure_ascii=False, indent=2)
        print(f"[OK] è®°å¿†çŠ¶æ€å·²ä¿å­˜: {memory_state_file}")
        
        # 5. åˆ›å»ºæ£€ç´¢å™¨
        print(f"\næ­¥éª¤ 3: åˆ›å»ºæ£€ç´¢å™¨")
        retrievers = {}
        
        # ç´¢å¼•æ£€ç´¢å™¨
        try:
            page_index_dir = os.path.join(sample_results_dir, "page_index")
            # å¦‚æœç´¢å¼•ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒï¼ˆé¿å… "Directory not empty" é”™è¯¯ï¼‰
            if os.path.exists(page_index_dir):
                import shutil
                shutil.rmtree(page_index_dir)
                print(f"[INFO] æ¸…ç†å·²å­˜åœ¨çš„é¡µé¢ç´¢å¼•ç›®å½•: {page_index_dir}")
            
            index_config = IndexRetrieverConfig(
                index_dir=page_index_dir
            )
            index_retriever = IndexRetriever(index_config.__dict__)
            index_retriever.build(page_store)
            retrievers["page_index"] = index_retriever
            print(f"[OK] ç´¢å¼•æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] ç´¢å¼•æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        # BM25 æ£€ç´¢å™¨
        try:
            bm25_index_dir = os.path.join(sample_results_dir, "bm25_index")
            # å¦‚æœç´¢å¼•ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒï¼ˆé¿å… "Directory not empty" é”™è¯¯ï¼‰
            if os.path.exists(bm25_index_dir):
                import shutil
                shutil.rmtree(bm25_index_dir)
                print(f"[INFO] æ¸…ç†å·²å­˜åœ¨çš„ BM25 ç´¢å¼•ç›®å½•: {bm25_index_dir}")
            
            bm25_config = BM25RetrieverConfig(
                index_dir=bm25_index_dir,
                threads=1
            )
            bm25_retriever = BM25Retriever(bm25_config.__dict__)
            bm25_retriever.build(page_store)
            retrievers["keyword"] = bm25_retriever
            print(f"[OK] BM25 æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] BM25 æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        # Dense æ£€ç´¢å™¨
        try:
            dense_index_dir = os.path.join(sample_results_dir, "dense_index")
            # å¦‚æœç´¢å¼•ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒï¼ˆé¿å… "Directory not empty" é”™è¯¯ï¼‰
            if os.path.exists(dense_index_dir):
                import shutil
                shutil.rmtree(dense_index_dir)
                print(f"[INFO] æ¸…ç†å·²å­˜åœ¨çš„ Dense ç´¢å¼•ç›®å½•: {dense_index_dir}")
            
            dense_config = DenseRetrieverConfig(
                index_dir=dense_index_dir,
                api_url="http://localhost:8001"  # API æ¨¡å¼ï¼šæ‰€æœ‰è¿›ç¨‹å…±äº«ä¸€ä¸ªæ¨¡å‹æœåŠ¡
            )
            dense_retriever = DenseRetriever(dense_config.__dict__)
            dense_retriever.build(page_store)
            retrievers["vector"] = dense_retriever
            print(f"[OK] Dense æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] Dense æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        print(f"[INFO] æˆåŠŸåˆ›å»º {len(retrievers)} ä¸ªæ£€ç´¢å™¨")
        
        print(f"\næ­¥éª¤ 1: åˆ›å»º Generator")
        generator_config = VLLMGeneratorConfig(
            model_name="qwen2.5-14b-instruct",
            api_key="empty",
            base_url="http://localhost:8000/v1",
            temperature=0.3,
            max_tokens=2048
        )
        generator = VLLMGenerator(generator_config.__dict__)


        working_config = VLLMGeneratorConfig(
            model_name="qwen2.5-14b-instruct",
            api_key="empty",
            base_url="http://localhost:8000/v1",
            temperature=0.3,
            max_tokens=64
        )
        working_generator = VLLMGenerator(working_config.__dict__)
        print(f"[OK] Generator åˆ›å»ºå®Œæˆ")


        # 6. åˆ›å»º ResearchAgent
        print(f"\næ­¥éª¤ 4: åˆ›å»º ResearchAgent")
        research_agent = ResearchAgent(
            page_store=page_store,
            memory_store=memory_store,
            retrievers=retrievers,
            generator=generator,
            # system_prompts=system_prompts,
            max_iters=3
        )
        print(f"[OK] ResearchAgent åˆ›å»ºå®Œæˆ")
        
        # 7. è¿›è¡Œé—®ç­”ï¼ˆå¹¶è¡Œå¤„ç†é—®é¢˜ï¼‰
        print(f"\næ­¥éª¤ 5: è¿›è¡Œé—®ç­”")
        qas = collect_qa_items_for_sample(sample)
        print(f"å…±æœ‰ {len(qas)} ä¸ªé—®é¢˜éœ€è¦å›ç­”")
        
        # å°†è®°å¿†è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        final_memory_str = json.dumps(final_state.model_dump(), ensure_ascii=False, indent=2)
        
        # å®šä¹‰å¤„ç†å•ä¸ªé—®é¢˜çš„workerå‡½æ•°
        def process_question(qi_with_index):
            """å¤„ç†å•ä¸ªé—®é¢˜çš„workerå‡½æ•°"""
            i, qi = qi_with_index
            q = qi.get("question") or ""
            gold = qi.get("answer")
            cat = qi.get("category")
            
            print(f"\n--- é—®é¢˜ {i}/{len(qas)} ---")
            print(f"é—®é¢˜: {q}")
            print(f"æ ‡å‡†ç­”æ¡ˆ: {gold}")
            print(f"åˆ†ç±»: {cat}")
            
            if cat == 5:
                return None

            try:
                # ä½¿ç”¨ ResearchAgent è¿›è¡Œç ”ç©¶
                print(f"[é—®é¢˜ {i}] æ­£åœ¨è¿›è¡Œæ·±åº¦ç ”ç©¶...")
                result = research_agent.research(q)
                research_summary = result.integrated_memory
                print(f"[é—®é¢˜ {i}] [OK] ç ”ç©¶å®Œæˆï¼è¿­ä»£æ¬¡æ•°: {len(result.raw_memory.get('iterations', []))}")
                print(f"[é—®é¢˜ {i}] ç ”ç©¶æ‘˜è¦: {research_summary[:200]}...")
                
                # ä¿å­˜ç ”ç©¶è½¨è¿¹
                research_trace = {
                    "question": q,
                    "raw_memory": result.raw_memory,
                    "integrated_memory": result.integrated_memory,
                    "iterations": result.raw_memory.get("iterations", []),
                    "search_plans": result.raw_memory.get("search_plans", []),
                    "reflections": result.raw_memory.get("reflections", [])
                }
                
                # ä¿å­˜å•ä¸ªé—®é¢˜çš„ç ”ç©¶è½¨è¿¹
                trace_file = os.path.join(sample_results_dir, f"research_trace_q{i}.json")
                with open(trace_file, 'w', encoding='utf-8') as f:
                    json.dump(research_trace, f, ensure_ascii=False, indent=2)
                print(f"[é—®é¢˜ {i}] [INFO] ç ”ç©¶è½¨è¿¹å·²ä¿å­˜: {trace_file}")
                
                # åŸºäºç ”ç©¶ç»“æœç”Ÿæˆç­”æ¡ˆï¼ˆæ ¹æ®categoryé€‰æ‹©ä¸åŒpromptï¼‰
                print(f"[é—®é¢˜ {i}] ç”Ÿæˆç­”æ¡ˆ...")
                summary_answer = answer_with_summary(cat, research_summary, q, working_generator)
                memory_answer = answer_with_memory(cat, final_memory_str, q, working_generator)
                
                print(f"[é—®é¢˜ {i}] åŸºäºç ”ç©¶çš„ç­”æ¡ˆ: {summary_answer}")
                print(f"[é—®é¢˜ {i}] åŸºäºè®°å¿†çš„ç­”æ¡ˆ: {memory_answer}")
                
                qa_result = {
                    "question": q,
                    "gold_answer": gold,
                    "category": cat,
                    "research_summary": research_summary,
                    "summary_answer": summary_answer,
                    "memory_answer": memory_answer,
                    "iterations": len(result.raw_memory.get("iterations", [])),
                    "research_trace_file": trace_file
                }
                return qa_result
            
            except Exception as e:
                print(f"[é—®é¢˜ {i}] [ERROR] å¤„ç†é—®é¢˜å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                qa_result = {
                    "question": q,
                    "gold_answer": gold,
                    "category": cat,
                    "error": str(e)
                }
                return qa_result
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰é—®é¢˜
        qa_items_with_index = [(i, qi) for i, qi in enumerate(qas, 1)]
        
        print(f"ä½¿ç”¨ {thread_count} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç† {len(qa_items_with_index)} ä¸ªé—®é¢˜...")
        
        qa_results = []
        with ThreadPoolExecutor(max_workers=thread_count) as executor:
            results_list = list(tqdm(
                executor.map(process_question, qa_items_with_index),
                total=len(qa_items_with_index),
                desc="å¤„ç†é—®é¢˜"
            ))
        
        # è¿‡æ»¤æ‰Noneç»“æœï¼ˆcategory==5çš„é—®é¢˜ï¼‰
        qa_results = [r for r in results_list if r is not None]
        
        # ä¿å­˜ç»“æœ
        results_file = os.path.join(sample_results_dir, "qa_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(qa_results, f, ensure_ascii=False, indent=2)
        print(f"\n[OK] ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ä¿å­˜æ‰€æœ‰ç ”ç©¶è½¨è¿¹çš„æ±‡æ€»
        all_research_traces = []
        for i, qa_result in enumerate(qa_results, 1):
            if "research_trace_file" in qa_result:
                trace_file = qa_result["research_trace_file"]
                if os.path.exists(trace_file):
                    with open(trace_file, 'r', encoding='utf-8') as f:
                        trace_data = json.load(f)
                        all_research_traces.append({
                            "question_index": i,
                            "question": qa_result["question"],
                            "category": qa_result["category"],
                            "research_trace": trace_data
                        })
        
        if all_research_traces:
            traces_summary_file = os.path.join(sample_results_dir, "all_research_traces.json")
            with open(traces_summary_file, 'w', encoding='utf-8') as f:
                json.dump(all_research_traces, f, ensure_ascii=False, indent=2)
            print(f"[OK] æ‰€æœ‰ç ”ç©¶è½¨è¿¹æ±‡æ€»å·²ä¿å­˜åˆ°: {traces_summary_file}")
        
        # æ€»ç»“
        print(f"\n{'='*60}")
        print("å¤„ç†å®Œæˆç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æ ·æœ¬ID: {sample_id}")
        print(f"ä¼šè¯æ•°: {len(session_chunks)}")
        print(f"è®°å¿†æ‘˜è¦æ•°: {len(final_state.abstracts)}")
        print(f"å¤„ç†é—®é¢˜æ•°: {len(qa_results)}")
        print(f"ç ”ç©¶è½¨è¿¹æ–‡ä»¶æ•°: {len(all_research_traces)}")
        print(f"ç»“æœä¿å­˜åˆ°: {sample_results_dir}")
        print(f"  - QAç»“æœ: qa_results.json")
        print(f"  - è®°å¿†çŠ¶æ€: memory_state.json")
        print(f"  - ç ”ç©¶è½¨è¿¹æ±‡æ€»: all_research_traces.json")
        print(f"  - å•ä¸ªç ”ç©¶è½¨è¿¹: research_trace_q*.json")
        
        return qa_results
        
    except Exception as e:
        error_msg = f"å¤„ç†æ ·æœ¬ {sample_index} æ—¶å‡ºé”™: {str(e)}"
        print(f"ERROR: {error_msg}")
        import traceback
        traceback.print_exc()
        return []


# ========== ä¸»å‡½æ•° ==========

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="GAM æ¡†æ¶ + LoCoMo æ•°æ®é›†æµ‹è¯•")
    parser.add_argument("--data", type=str, default="/share/project/bingyu/datasets/locomo/locomo10.json", 
                        help="LoCoMo æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--outdir", type=str, default="/share/project/bingyu/code/general-agentic-memory/results/locomo_output",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--start-idx", type=int, default=0, help="å¼€å§‹æ ·æœ¬ç´¢å¼•")
    parser.add_argument("--end-idx", type=int, default=None, help="ç»“æŸæ ·æœ¬ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬")
    parser.add_argument("--thread-count", type=int, default=40, help="å¹¶è¡Œå¤„ç†é—®é¢˜çš„çº¿ç¨‹æ•°ï¼ˆæ¯ä¸ªæ ·æœ¬å†…éƒ¨ï¼‰")
    parser.add_argument("--memory-model-api", type=str, default="http://localhost:8000/v1", help="è®°å¿†æ¨¡å‹API")
    args = parser.parse_args()
    
    print("=" * 60)
    print("GAM æ¡†æ¶ + LoCoMo æ•°æ®é›†æµ‹è¯•")
    print("=" * 60)
    print(f"æ•°æ®é›†: {args.data}")
    print(f"è¾“å‡ºç›®å½•: {args.outdir}")
    print(f"æ ·æœ¬èŒƒå›´: {args.start_idx} åˆ° {args.end_idx-1 if args.end_idx else 'å…¨éƒ¨'} (å…± {args.end_idx - args.start_idx if args.end_idx else 'å…¨éƒ¨'} ä¸ªæ ·æœ¬)")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    samples = load_locomo(args.data)
    print(f"å…±åŠ è½½ {len(samples)} ä¸ªæ ·æœ¬")
    
    # é‡æ–°è®¾ç½®ç»“æŸç´¢å¼•ï¼ˆåœ¨åŠ è½½æ•°æ®åï¼‰
    if args.end_idx is None:
        args.end_idx = len(samples)
    
    print(f"å®é™…å¤„ç†èŒƒå›´: {args.start_idx} åˆ° {args.end_idx-1} (å…± {args.end_idx - args.start_idx} ä¸ªæ ·æœ¬)")
    
    # éªŒè¯ç´¢å¼•èŒƒå›´
    if args.start_idx < 0 or args.start_idx >= len(samples):
        print(f"é”™è¯¯: å¼€å§‹æ ·æœ¬ç´¢å¼• {args.start_idx} è¶…å‡ºèŒƒå›´ (æ€»æ ·æœ¬æ•°: {len(samples)})")
        return
    
    if args.end_idx > len(samples):
        print(f"è­¦å‘Š: ç»“æŸæ ·æœ¬ç´¢å¼• {args.end_idx} è¶…å‡ºèŒƒå›´ï¼Œè°ƒæ•´ä¸º {len(samples)}")
        args.end_idx = len(samples)
    
    if args.start_idx >= args.end_idx:
        print(f"é”™è¯¯: å¼€å§‹ç´¢å¼• {args.start_idx} å¿…é¡»å°äºç»“æŸç´¢å¼• {args.end_idx}")
        return
    
    # é¡ºåºå¤„ç†æ¯ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å†…éƒ¨å¹¶è¡Œå¤„ç†é—®é¢˜
    sample_indices = list(range(args.start_idx, args.end_idx))
    thread_count = args.thread_count
    
    print(f"å°†é¡ºåºå¤„ç† {len(sample_indices)} ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å†…éƒ¨ä½¿ç”¨ {thread_count} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†é—®é¢˜...")
    
    all_results = []
    
    # é¡ºåºå¤„ç†æ¯ä¸ªæ ·æœ¬
    for sample_idx in tqdm(sample_indices, desc="å¤„ç†æ ·æœ¬"):
        sample = samples[sample_idx]
        print(f"\n{'='*80}")
        print(f"å¼€å§‹å¤„ç†æ ·æœ¬ {sample_idx}/{len(samples)-1} (èŒƒå›´: {args.start_idx}-{args.end_idx-1})")
        print(f"{'='*80}")
        
        try:
            results = process_sample(sample, sample_idx, args.outdir, args.memory_model_api, thread_count)
            print(f"[OK] æ ·æœ¬ {sample_idx} å¤„ç†å®Œæˆ")
            all_results.extend(results)
        except Exception as e:
            print(f"[ERROR] æ ·æœ¬ {sample_idx} å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ä¿å­˜æ‰€æœ‰ç»“æœæ±‡æ€»
    if all_results:
        summary_file = os.path.join(args.outdir, f"batch_results_{args.start_idx}_{args.end_idx-1}.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\n[OK] æ‰¹é‡ç»“æœæ±‡æ€»å·²ä¿å­˜: {summary_file}")
    
    print(f"\n{'='*60}")
    print("[OK] æ‰¹é‡æµ‹è¯•å®Œæˆï¼")
    print(f"å¤„ç†æ ·æœ¬æ•°: {args.end_idx - args.start_idx}")
    print(f"æˆåŠŸå¤„ç†: {len(all_results)} ä¸ªé—®é¢˜")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()

